/**
 * LR parser generated by the Syntax tool.
 *
 * https://www.npmjs.com/package/syntax-cli
 *
 *   npm install -g syntax-cli
 *
 *   syntax-cli --help
 *
 * To regenerate run:
 *
 *   syntax-cli \
 *     --grammar ~/path-to-grammar-file \
 *     --mode <parsing-mode> \
 *     --output ~/path-to-output-parser-file.js
 */

'use strict';



let yytext;
let yyleng;
let $$;

const EOF = {
  toString() {
    return '$';
  }
};

const ps = [[-1, 1],
[0, 2, ($1,$2) => { return $$ = {bnf: $2 }; }],
[1, 2, ($1,$2) => { $$ = $1; $$[$2[0]] = $2[1]; }],
[1, 1, ($1) => { $$ = {}; $$[$1[0]] = $1[1]; }],
[2, 4, ($1,$2,$3,$4) => { $$ = [$1, $3]; }],
[3, 1, ($1) => { $$ = yytext; }],
[4, 3, ($1,$2,$3) => { $$ = $1; $$.push($3); }],
[4, 1, ($1) => { $$ = [$1]; }],
[5, 2, ($1,$2) => { $$ = [$1, $2]; }],
[6, 1, ($1) => { $$ = $1; }],
[6, 0, () => { $$ = ''; }],
[7, 2, ($1,$2) => { $$ = $1 + ' ' + $2; }],
[7, 1, ($1) => { $$ = $1; }],
[8, 1, ($1) => { $$ = yytext; }],
[8, 1, ($1) => { $$ = yytext; }],
[9, 1, ($1) => { $$ = yytext; }],
[9, 0, () => { $$ = null; }]];
const tks = {"%%":10,"SPLITTER":11,";":12,"ID":13,"|":14,"STRING":15,"CODE":16,"$":17};
const tbl = {"0":{"0":20,"10":"s1"},"1":{"1":2,"2":3,"3":4,"13":"s21"},"2":{"2":5,"3":4,"13":"s21","17":"r1"},"3":{"13":"r3","17":"r3"},"4":{"11":"s6"},"5":{"13":"r2","17":"r2"},"6":{"4":7,"5":8,"6":9,"7":10,"8":11,"12":"r10","13":"s12","14":"r10","15":"s13","16":"r10"},"7":{"12":"s14","14":"s15"},"8":{"12":"r7","14":"r7"},"9":{"9":17,"12":"r16","14":"r16","16":"s18"},"10":{"8":19,"12":"r9","13":"s12","14":"r9","15":"s13","16":"r9"},"11":{"12":"r12","13":"r12","14":"r12","15":"r12","16":"r12"},"12":{"12":"r13","13":"r13","14":"r13","15":"r13","16":"r13"},"13":{"12":"r14","13":"r14","14":"r14","15":"r14","16":"r14"},"14":{"13":"r4","17":"r4"},"15":{"5":16,"6":9,"7":10,"8":11,"12":"r10","13":"s12","14":"r10","15":"s13","16":"r10"},"16":{"12":"r6","14":"r6"},"17":{"12":"r8","14":"r8"},"18":{"12":"r15","14":"r15"},"19":{"12":"r11","13":"r11","14":"r11","15":"r11","16":"r11"},"20":{"17":"acc"},"21":{"11":"r5"}};

let s = [];

function unexpectedToken(token) {
  if (token.value === EOF) {
    unexpectedEndOfInput();
  }
  parseError(`Unexpected token: ${token.value}.`);
}

function unexpectedEndOfInput() {
  parseError(`Unexpected end of input.`);
}

function parseError(message) {
  throw new Error(`Parse error: ${message}`);
}

let tokenizer;
/**
 * Generic tokenizer used by the parser in the Syntax tool.
 *
 * https://www.npmjs.com/package/syntax-cli
 *
 * See `--custom-tokinzer` to skip this generation, and use a custom one.
 */

const lexRules = [[/^\/\*(.|\s)*?\*\//, () => { /* skip comments */ }],
[/^\s+/, () => { /* skip whitespace */ }],
[/^\{\s*(.*)\s*\}/, () => { yytext = yytext.slice(1, -1).trim(); return 'CODE' }],
[/^[a-zA-Z][a-zA-Z0-9_-]*/, () => { return 'ID' }],
[/^(?:->|:)/, () => { return 'SPLITTER' }],
[/^;/, () => { return ';' }],
[/^\|/, () => { return '|' }],
[/^\{/, () => { return '{' }],
[/^\}/, () => { return '}' }],
[/^%%/, () => { return '%%' }],
[/^(?:"|')([^"']*)(?:"|')/, () => { return 'STRING' }]];

tokenizer = {
  initString(string) {
    this._string = string + EOF;
    this._cursor = 0;
    return this;
  },

  getNextToken() {
    if (!this.hasMoreTokens()) {
      return {
        type: EOF,
        value: EOF,
      };
    } else if (this.isEOF()) {
      this._cursor++;
      return {
        type: EOF,
        value: EOF,
      };
    }

    let string = this._string.slice(this._cursor);

    for (let i = 0; i < lexRules.length; i++) {
      let lexRule = lexRules[i];
      let matched = this._match(string, lexRule[0]);
      if (matched) {
        yytext = matched;
        yyleng = yytext.length;
        let token = lexRule[1]();

        if (!token) {
          return this.getNextToken();
        }

        return {
          type: token,
          value: yytext,
        };
      }
    }

    throw new Error(`Unexpected token: "${string[0]}".`);
  },

  isEOF() {
    return this._string[this._cursor] === EOF.toString() &&
      this._cursor === this._string.length - 1;
  },

  hasMoreTokens() {
    return this._cursor < this._string.length;
  },

  _match(string, regexp) {
    let matched = string.match(regexp);
    if (matched) {
      this._cursor += matched[0].length;
      return matched[0];
    }
    return null;
  },
};

function onParseBegin($1) {
  
  LRParser.onParseBegin($1);
}

function onParseEnd($1) {
  
  LRParser.onParseEnd($1);
}

const LRParser = {
  parse(string) {
    onParseBegin(string);

    if (!tokenizer) {
      throw new Error(`Tokenizer instance wasn't specified.`);
    }

    tokenizer.initString(string);

    s = [];

    s.push(0);

    let t = tokenizer.getNextToken();
    let st = null;

    do {
      if (!t) {
        unexpectedEndOfInput();
      }

      let sta = s[s.length - 1];
      let clm = tks[t.type];
      let e = tbl[sta][clm];

      if (!e) {
        unexpectedToken(t);
      }

      if (e[0] === 's') {
        s.push(
          {symbol: t.type, semanticValue: t.value},
          Number(e.slice(1))
        );
        st = t;
        t = tokenizer.getNextToken();
      } else if (e[0] === 'r') {
        let pn = e.slice(1);
        let p = ps[pn];
        let hsa = typeof p[2] === 'function';
        let saa = hsa ? [] : null;

        if (p[1] !== 0) {
          let rhsl = p[1];
          while (rhsl--) {
            s.pop();
            let se = s.pop();

            if (hsa) {
              saa.unshift(se.semanticValue);
            }
          }
        }

        let rse = {symbol: p[0]};

        if (hsa) {
          yytext = st ? st.value : null;
          yyleng = st ? st.value.length : null;

          p[2](...saa);
          rse.semanticValue = $$;
        }

        s.push(
          rse,
          tbl[s[s.length - 1]][p[0]]
        );
      } else if (e === 'acc') {
        s.pop();
        let parsed = s.pop();

        if (s.length !== 1 ||
            s[0] !== 0 ||
            tokenizer.hasMoreTokens()) {
          unexpectedToken(t);
        }

        if (parsed.hasOwnProperty('semanticValue')) {
          onParseEnd(parsed.semanticValue);
          return parsed.semanticValue;
        }

        onParseEnd();
        return true;
      }

    } while (tokenizer.hasMoreTokens() || s.length > 1);
  },

  setTokenizer(customTokenizer) {
    tokenizer = customTokenizer;
    return this;
  },

  getTokenizer() {
    return tokenizer;
  },

  onParseBegin(string) {},
  onParseEnd(parsed) {},

};

module.exports = LRParser;
