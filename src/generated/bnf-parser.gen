/**
 * LR parser generated by the Syntax tool.
 *
 * https://www.npmjs.com/package/syntax-cli
 *
 *   npm install -g syntax-cli
 *
 *   syntax-cli --help
 *
 * To regenerate run:
 *
 *   syntax-cli \
 *     --grammar ~/path-to-grammar-file \
 *     --mode <parsing-mode> \
 *     --output ~/path-to-output-parser-file.js
 */

'use strict';

let yytext;
let yyleng;
let $$;

const EOF = {
  toString() {
    return '$';
  }
};

const ps = [[-1, 1],
[0, 3, ($1,$2,$3) => { 
                            const spec = Object.assign({bnf: $3}, extra);

                            if (operators.length) {
                              spec.operators = operators;
                            }

                            if (tokens.length) {
                              spec.tokens = tokens.join(' ');
                            }

                            $$ = spec;
                           }],
[1, 1],
[1, 2],
[2, 1, ($1) => { extra.moduleInclude = $1 }],
[2, 2, ($1,$2) => { extra.start = $2 }],
[2, 2, ($1,$2) => { operators.push(['left'].concat($2)) }],
[2, 2, ($1,$2) => { operators.push(['right'].concat($2)) }],
[2, 2, ($1,$2) => { operators.push(['nonassoc'].concat($2)) }],
[2, 2, ($1,$2) => { tokens.push($2) }],
[2, 0],
[3, 1, ($1) => { $$ = [$1] }],
[3, 2, ($1,$2) => { $$ = $1; $1.push($2) }],
[4, 2, ($1,$2) => { $$ = $1; $$[$2[0]] = $2[1] }],
[4, 1, ($1) => { $$ = {}; $$[$1[0]] = $1[1] }],
[5, 4, ($1,$2,$3,$4) => { $$ = [$1, $3] }],
[6, 1, ($1) => { $$ = $1 }],
[7, 3, ($1,$2,$3) => { $$ = $1; $1.push($3) }],
[7, 1, ($1) => { $$ = [$1] }],
[8, 2, ($1,$2) => { $$ = [$1[0], $2]; $1[1] && $$.push({prec: $1[1]}) }],
[9, 2, ($1,$2) => { $$ = [$1, $2] }],
[9, 0, () => { $$ = '' }],
[10, 2, ($1,$2) => { $$ = $2 }],
[10, 0],
[11, 2, ($1,$2) => { $$ = $1 + ' ' + $2 }],
[11, 1, ($1) => { $$ = $1 }],
[12, 1, ($1) => { $$ = $1 }],
[12, 1, ($1) => { $$ = $1 }],
[13, 1, ($1) => { $$ = $1 }],
[13, 1, ($1) => { $$ = $1 }],
[14, 1, ($1) => { $$ = $1.slice(1, -1) }],
[15, 1, ($1) => { $$ = $1 }],
[15, 0, () => { $$ = null }]];
const tks = {"%%":16,"MODULE_INCLUDE":17,"%start":18,"%left":19,"%right":20,"%nonassoc":21,"%token":22,"ID":23,"SPLITTER":24,";":25,"|":26,"%prec":27,"STRING":28,"CODE":29,"$":30};
const tbl = {"0":{"0":42,"1":1,"2":2,"16":"r10","17":"s3/r10","18":"s4/r10","19":"s5/r10","20":"s6/r10","21":"s7/r10","22":"s8/r10"},"1":{"2":10,"16":"s9/r10","17":"s3/r10","18":"s4/r10","19":"s5/r10","20":"s6/r10","21":"s7/r10","22":"s8/r10"},"2":{"16":"r2","17":"r2","18":"r2","19":"r2","20":"r2","21":"r2","22":"r2"},"3":{"16":"r4","17":"r4","18":"r4","19":"r4","20":"r4","21":"r4","22":"r4"},"4":{"6":32,"23":"s43"},"5":{"3":33,"13":34,"14":36,"23":"s35","28":"s37"},"6":{"3":39,"13":34,"14":36,"23":"s35","28":"s37"},"7":{"3":40,"13":34,"14":36,"23":"s35","28":"s37"},"8":{"23":"s41"},"9":{"4":11,"5":12,"6":13,"23":"s43"},"10":{"16":"r3","17":"r3","18":"r3","19":"r3","20":"r3","21":"r3","22":"r3"},"11":{"5":14,"6":13,"23":"s43","30":"r1"},"12":{"23":"r14","30":"r14"},"13":{"24":"s15"},"14":{"23":"r13","30":"r13"},"15":{"7":16,"8":17,"9":18,"11":19,"12":20,"23":"s21","25":"r21","26":"r21","28":"s22","29":"r21"},"16":{"25":"s23","26":"s24"},"17":{"25":"r18","26":"r18"},"18":{"15":26,"25":"r32","26":"r32","29":"s27"},"19":{"10":28,"12":29,"23":"s21","25":"r23","26":"r23","27":"s30","28":"s22","29":"r23"},"20":{"23":"r25","25":"r25","26":"r25","27":"r25","28":"r25","29":"r25"},"21":{"23":"r26","25":"r26","26":"r26","27":"r26","28":"r26","29":"r26"},"22":{"23":"r27","25":"r27","26":"r27","27":"r27","28":"r27","29":"r27"},"23":{"23":"r15","30":"r15"},"24":{"8":25,"9":18,"11":19,"12":20,"23":"s21","25":"r21","26":"r21","28":"s22","29":"r21"},"25":{"25":"r17","26":"r17"},"26":{"25":"r19","26":"r19"},"27":{"25":"r31","26":"r31"},"28":{"25":"r20","26":"r20","29":"r20"},"29":{"23":"r24","25":"r24","26":"r24","27":"r24","28":"r24","29":"r24"},"30":{"12":31,"23":"s21","28":"s22"},"31":{"25":"r22","26":"r22","29":"r22"},"32":{"16":"r5","17":"r5","18":"r5","19":"r5","20":"r5","21":"r5","22":"r5"},"33":{"13":38,"14":36,"16":"r6","17":"r6","18":"r6","19":"r6","20":"r6","21":"r6","22":"r6","23":"s35","28":"s37"},"34":{"16":"r11","17":"r11","18":"r11","19":"r11","20":"r11","21":"r11","22":"r11","23":"r11","28":"r11"},"35":{"16":"r28","17":"r28","18":"r28","19":"r28","20":"r28","21":"r28","22":"r28","23":"r28","28":"r28"},"36":{"16":"r29","17":"r29","18":"r29","19":"r29","20":"r29","21":"r29","22":"r29","23":"r29","28":"r29"},"37":{"16":"r30","17":"r30","18":"r30","19":"r30","20":"r30","21":"r30","22":"r30","23":"r30","28":"r30"},"38":{"16":"r12","17":"r12","18":"r12","19":"r12","20":"r12","21":"r12","22":"r12","23":"r12","28":"r12"},"39":{"13":38,"14":36,"16":"r7","17":"r7","18":"r7","19":"r7","20":"r7","21":"r7","22":"r7","23":"s35","28":"s37"},"40":{"13":38,"14":36,"16":"r8","17":"r8","18":"r8","19":"r8","20":"r8","21":"r8","22":"r8","23":"s35","28":"s37"},"41":{"16":"r9","17":"r9","18":"r9","19":"r9","20":"r9","21":"r9","22":"r9"},"42":{"30":"acc"},"43":{"16":"r16","17":"r16","18":"r16","19":"r16","20":"r16","21":"r16","22":"r16","24":"r16"}};

const s = [];

let tokenizer;
/**
 * Generic tokenizer used by the parser in the Syntax tool.
 *
 * https://www.npmjs.com/package/syntax-cli
 *
 * See `--custom-tokinzer` to skip this generation, and use a custom one.
 */

const lexRules = [[/^\/\*(.|\s)*?\*\//, () => { /* skip comments */ }],
[/^\s+/, () => { /* skip whitespace */ }],
[/^%start/, () => { return '%start' }],
[/^%prec/, () => { return '%prec' }],
[/^%left/, () => { return '%left' }],
[/^%right/, () => { return '%right' }],
[/^%nonassoc/, () => { return '%nonassoc' }],
[/^%token/, () => { return '%token' }],
[/^%lex[wW]*?\/lex/, () => { return 'LEX_BLOCK' }],
[/^%\{(.|\r|\n)*?%\}/, () => { yytext = yytext.slice(2, -2).trim(); return 'MODULE_INCLUDE' }],
[/^\{\s*(.*)\s*\}/, () => { yytext = yytext.slice(1, -1).trim(); return 'CODE' }],
[/^[a-zA-Z][a-zA-Z0-9_-]*/, () => { return 'ID' }],
[/^(?:->|:)/, () => { return 'SPLITTER' }],
[/^;/, () => { return ';' }],
[/^\|/, () => { return '|' }],
[/^\{/, () => { return '{' }],
[/^\}/, () => { return '}' }],
[/^%%/, () => { return '%%' }],
[/^%[a-zA-Z]+[^\r\n]*/, () => { /* skip unrecognized options */ }],
[/^(?:"|')([^"']*)(?:"|')/, () => { return 'STRING' }]];

tokenizer = {
  initString(string) {
    this._string = string + EOF;
    this._cursor = 0;
    return this;
  },

  getNextToken() {
    if (!this.hasMoreTokens()) {
      return {
        type: EOF,
        value: EOF,
      };
    } else if (this.isEOF()) {
      this._cursor++;
      return {
        type: EOF,
        value: EOF,
      };
    }

    let string = this._string.slice(this._cursor);

    for (let i = 0; i < lexRules.length; i++) {
      let lexRule = lexRules[i];
      let matched = this._match(string, lexRule[0]);
      if (matched) {
        yytext = matched;
        yyleng = yytext.length;
        let token = lexRule[1]();

        if (!token) {
          return this.getNextToken();
        }

        return {
          type: token,
          value: yytext,
        };
      }
    }

    throw new Error(`Unexpected token: "${string[0]}".`);
  },

  isEOF() {
    return this._string[this._cursor] === EOF.toString() &&
      this._cursor === this._string.length - 1;
  },

  hasMoreTokens() {
    return this._cursor < this._string.length;
  },

  _match(string, regexp) {
    let matched = string.match(regexp);
    if (matched) {
      this._cursor += matched[0].length;
      return matched[0];
    }
    return null;
  },
};

const yyparse = {
  parse(string) {
    yyparse.onParseBegin(string);

    if (!tokenizer) {
      throw new Error(`Tokenizer instance wasn't specified.`);
    }

    tokenizer.initString(string);

    s.length = 0;
    s.push(0);

    let t = tokenizer.getNextToken();
    let st = null;

    do {
      if (!t) {
        unexpectedEndOfInput();
      }

      let sta = s[s.length - 1];
      let clm = tks[t.type];
      let e = tbl[sta][clm];

      if (!e) {
        unexpectedToken(t);
      }

      if (e[0] === 's') {
        s.push(
          {symbol: t.type, semanticValue: t.value},
          Number(e.slice(1))
        );
        st = t;
        t = tokenizer.getNextToken();
      } else if (e[0] === 'r') {
        let pn = e.slice(1);
        let p = ps[pn];
        let hsa = typeof p[2] === 'function';
        let saa = hsa ? [] : null;

        if (p[1] !== 0) {
          let rhsl = p[1];
          while (rhsl--) {
            s.pop();
            let se = s.pop();

            if (hsa) {
              saa.unshift(se.semanticValue);
            }
          }
        }

        let rse = {symbol: p[0]};

        if (hsa) {
          yytext = st ? st.value : null;
          yyleng = st ? st.value.length : null;

          p[2](...saa);
          rse.semanticValue = $$;
        }

        s.push(
          rse,
          tbl[s[s.length - 1]][p[0]]
        );
      } else if (e === 'acc') {
        s.pop();
        let parsed = s.pop();

        if (s.length !== 1 ||
            s[0] !== 0 ||
            tokenizer.hasMoreTokens()) {
          unexpectedToken(t);
        }

        if (parsed.hasOwnProperty('semanticValue')) {
          yyparse.onParseEnd(parsed.semanticValue);
          return parsed.semanticValue;
        }

        yyparse.onParseEnd();
        return true;
      }

    } while (tokenizer.hasMoreTokens() || s.length > 1);
  },

  setTokenizer(customTokenizer) {
    tokenizer = customTokenizer;
    return yyparse;
  },

  getTokenizer() {
    return tokenizer;
  },

  onParseBegin(string) {},
  onParseEnd(parsed) {},
};


      let tokens;
      let operators;
      let extra;

      yyparse.onParseBegin = () => {
        tokens = [];
        operators = [];
        extra = {};
      };
    

function unexpectedToken(token) {
  if (token.value === EOF) {
    unexpectedEndOfInput();
  }
  parseError(`Unexpected token: ${token.value}.`);
}

function unexpectedEndOfInput() {
  parseError(`Unexpected end of input.`);
}

function parseError(message) {
  throw new Error(`Parse error: ${message}`);
}

module.exports = yyparse;
